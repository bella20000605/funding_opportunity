name: Weekly funding opportunity scraper and Email Sender

# on:
#   schedule:
#     # Runs at 9:00 AM ET (14:00 UTC) every Monday
#     - cron: '0 14 * * 1'
on:
  schedule:
    # Runs at 2:13 PM ET (19:13 UTC) every Tuesday
    - cron: '13 19 * * 2'

  workflow_dispatch: # Allows manual triggering

jobs:

  run-scraper-and-send-email:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository code
      - name: Checkout code
        uses: actions/checkout@v3


      # Step 2: Set up Python 3.11
      - name: Set up Python 3.11
        uses: actions/setup-python@v4  # Correct version for Python setup
        with:
          python-version: '3.11'

      # Step 3: Install Poetry
      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install poetry

      # Step 4: Install dependencies using Poetry
      - name: Install dependencies
        run: |
          poetry install

      # Step 5: Install Chrome for the GitHub Actions (Ubuntu)
      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable


      # The webdriver-manager will handle downloading and setting up the correct ChromeDriver version when you run your scraper.

      # Step 6: Run the scraper Python script using Poetry
      - name: Run the scraper script
        run: |
          poetry run python funding_opportunity/scraper.py

      # Step 8: Create client_secret.json automaticlly from GitHub Secret
      - name: Create client_secret.json
        run: |
          echo "$CLIENT_SECRET_JSON" > funding_opportunity/client_secret.json
        env:
          CLIENT_SECRET_JSON: ${{ secrets.CLIENT_SECRET_JSON }}

      # Step 9: Run the email-sending Python script using Poetry
      - name: Run weekly email script
        run: |
          poetry run python funding_opportunity/send_email.py